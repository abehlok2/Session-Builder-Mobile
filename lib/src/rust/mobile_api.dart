// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.11.1.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'frb_generated.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';

// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `ENGINE`, `EngineState`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `deref`, `fmt`, `initialize`

Future<void> startAudioSession({
  required String trackJson,
  double? startTime,
}) => RustLib.instance.api.crateMobileApiStartAudioSession(
  trackJson: trackJson,
  startTime: startTime,
);

Future<void> stopAudioSession() =>
    RustLib.instance.api.crateMobileApiStopAudioSession();

Future<void> pauseAudio() => RustLib.instance.api.crateMobileApiPauseAudio();

Future<void> resumeAudio() => RustLib.instance.api.crateMobileApiResumeAudio();

Future<void> setVolume({required double volume}) =>
    RustLib.instance.api.crateMobileApiSetVolume(volume: volume);

Future<void> updateSession({required String trackJson}) =>
    RustLib.instance.api.crateMobileApiUpdateSession(trackJson: trackJson);

Future<void> pushClipChunk({
  required BigInt index,
  required List<double> samples,
  required bool finished,
}) => RustLib.instance.api.crateMobileApiPushClipChunk(
  index: index,
  samples: samples,
  finished: finished,
);

/// Seek to a specific position in the audio stream (in seconds)
/// Maps to Python's start_from function
Future<void> startFrom({required double position}) =>
    RustLib.instance.api.crateMobileApiStartFrom(position: position);

/// Enable or disable GPU acceleration for audio processing
/// Maps to Python's enable_gpu function
Future<void> enableGpu({required bool enable}) =>
    RustLib.instance.api.crateMobileApiEnableGpu(enable: enable);

/// Render up to 60 seconds of audio to a WAV file
/// Maps to Python's render_sample_wav function
Future<void> renderSampleWav({
  required String trackJson,
  required String outPath,
}) => RustLib.instance.api.crateMobileApiRenderSampleWav(
  trackJson: trackJson,
  outPath: outPath,
);

/// Render the complete audio track to a WAV file
/// Maps to Python's render_full_wav function
Future<void> renderFullWav({
  required String trackJson,
  required String outPath,
}) => RustLib.instance.api.crateMobileApiRenderFullWav(
  trackJson: trackJson,
  outPath: outPath,
);

/// Set the master output gain (volume)
/// Alias for set_volume to match Python API naming
Future<void> setMasterGain({required double gain}) =>
    RustLib.instance.api.crateMobileApiSetMasterGain(gain: gain);

/// Get the current playback status
Future<bool> isAudioPlaying() =>
    RustLib.instance.api.crateMobileApiIsAudioPlaying();

/// Get the current sample rate of the active session
Future<int?> getSampleRate() =>
    RustLib.instance.api.crateMobileApiGetSampleRate();

/// Generate waveform data for visualization
/// Returns amplitude values (0.0 to 1.0) sampled at regular intervals
/// for the given duration in seconds
Future<Float32List> generateWaveformSnippet({required double durationSec}) =>
    RustLib.instance.api.crateMobileApiGenerateWaveformSnippet(
      durationSec: durationSec,
    );

/// Generate waveform data from a track JSON configuration
/// This creates waveform visualization based on the step structure
Future<Float32List> generateTrackWaveform({
  required String trackJson,
  required int samplesPerSecond,
}) => RustLib.instance.api.crateMobileApiGenerateTrackWaveform(
  trackJson: trackJson,
  samplesPerSecond: samplesPerSecond,
);

/// Get the current playback position in seconds
/// Returns None if no audio session is active
Future<double?> getPlaybackPosition() =>
    RustLib.instance.api.crateMobileApiGetPlaybackPosition();

/// Get the number of elapsed samples since playback started
/// Returns None if no audio session is active
Future<BigInt?> getElapsedSamples() =>
    RustLib.instance.api.crateMobileApiGetElapsedSamples();

/// Get the current step index (0-based)
/// Returns None if no audio session is active
Future<BigInt?> getCurrentStep() =>
    RustLib.instance.api.crateMobileApiGetCurrentStep();

/// Check if playback is currently paused
/// Returns None if no audio session is active
Future<bool?> getIsPaused() => RustLib.instance.api.crateMobileApiGetIsPaused();

/// Get complete playback status as a struct
/// Returns position in seconds, current step index, and paused state
/// Returns None if no audio session is active
Future<PlaybackStatus?> getPlaybackStatus() =>
    RustLib.instance.api.crateMobileApiGetPlaybackStatus();

/// Playback status information returned by get_playback_status
class PlaybackStatus {
  /// Current playback position in seconds
  final double positionSeconds;

  /// Current step index (0-based)
  final BigInt currentStep;

  /// Whether playback is paused
  final bool isPaused;

  /// Sample rate of the audio session
  final int sampleRate;

  const PlaybackStatus({
    required this.positionSeconds,
    required this.currentStep,
    required this.isPaused,
    required this.sampleRate,
  });

  @override
  int get hashCode =>
      positionSeconds.hashCode ^
      currentStep.hashCode ^
      isPaused.hashCode ^
      sampleRate.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is PlaybackStatus &&
          runtimeType == other.runtimeType &&
          positionSeconds == other.positionSeconds &&
          currentStep == other.currentStep &&
          isPaused == other.isPaused &&
          sampleRate == other.sampleRate;
}
